---
output: github_document
bibliography: references.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# tensr

<!-- badges: start -->

[![R-CMD-check](https://github.com/lschneiderbauer/tensr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/lschneiderbauer/tensr/actions/workflows/R-CMD-check.yaml) [![Codecov test coverage](https://codecov.io/gh/lschneiderbauer/tensr/graph/badge.svg)](https://app.codecov.io/gh/lschneiderbauer/tensr)
[![CRAN status](https://www.r-pkg.org/badges/version/tensr)](https://CRAN.R-project.org/package=tensr)
<!-- badges: end -->

The goal of tensr is to provide a *compact* R interface for performing [tensor calculations](https://en.wikipedia.org/wiki/Ricci_calculus). This is achieved by labeling (upper and lower) index slots of R's `array` and making use of Ricci calculus conventions to implicitly trigger contractions and diagonal subsetting. Explicit tensor operations, such as addition, multiplication of tensors, raising and lowering indices, or the Kronecker product are also available. Common tensors like the Kronecker delta, Levi Civita epsilon, and common metric tensors are provided.

Under the hood calculations are performed using the [calculus](https://calculus.eguidotti.com/) package [@guidotti2022]. tensr provides an alternative interface to some of its functionality.

## Installation

You can install the development version of tensr from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("lschneiderbauer/tensr")
```

## Example

The central object is R's `array`. Adding index slot labels allows us to perform common tensor operations implicitly.

For demonstration purposes we use an arbitrary array of rank 3.

```{r example}
library(tensr)

# the data
a <- array(1:(2^2*3), dim = c(2,2,3))
```

### Creating a labeled tensor

We can use `a` to create a labeled tensor with lower index labels i, j, and k:

$$
a_{ijk}
$$

```{r}
a %_% .(i, j, k)
```

By default, indices are assumed to be lower indices. We can use a "+" prefix to create an upper index label.

$$
a_{ij}^{\;\;k}
$$

```{r}
a %_% .(i, j, +k)
```

### Performing calculations

Simply creating labels is not very interesting. The act of labeling tensor index slots becomes useful when the labels are such that they trigger implicit calculations, or they are combined with other tensors via multiplication or addition.

#### Contraction

Repeated index labels with opposite position are implicitly contracted.

$$
b_j=a_{i\;k}^{\;i}
$$

```{r}
a %_% .(i, +i, k)
```

#### Diagonal subsetting

Repeated labels on the same position (upper or lower) will trigger diagonal subsetting.

$$
c_{ik}=a_{iik}
$$

```{r}
a %_% .(i, i, k)
```

#### Outer tensor product

The same conventions apply for arbitrary tensor multiplication.

$$
d_{ijklmn}=a_{ijk}a_{lmn}
$$

```{r}
a %_% .(i, j, k) * a %_% .(l, m, n)
```

#### Tensor multiplication w/ contractions

$$
e=a_{ijk}a^{ijk}
$$

```{r}
a %_% .(i, j, k) * a %_% .(+i, +j, +k)
```

#### Tensor multiplication w/ contractions and subsetting

$$
f_j=a_{ijk}a^{i\;k}_{\;j}
$$

```{r}
a %_% .(i, j, k) * a %_% .(+i, j, +k)
```

#### Tensor addition

Tensor addition is taking care of correct index slot matching (by index labels), so the position of the index does not matter.

$$
g_{ijk} = a_{ijk} + a_{jik}
$$

```{r}
a %_% .(i, j, k) + a %_% .(j, i, k)
```
